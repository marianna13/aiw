<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description"
    content="Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models">
  <meta property="og:title" content="AIW Project page" />
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
  <meta property="og:url" content="marianna13.github.io/aiw" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>AIW</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">üé©üêá Alice in Wonderland: Simple Tasks Showing Complete Reasoning
              Breakdown in State-Of-the-Art Large Language Models</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://github.com/marianna13" target="_blank">Marianna Nezhurina</a><sup>1,2,4*</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=CSU2BuMAAAAJ&hl=en" target="_blank">Lucia
                  Cipolina-Kun</a><sup>1,2,3</sup>,</span>
              <span class="author-block">
                <a href="https://mehdidc.github.io/" target="_blank">Mehdi Cherti</a><sup>1,2,4</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.de/citations?user=p1FuAMkAAAAJ&hl=en" target="_blank">Jenia
                  Jitsev</a><sup>1,2,4*</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>LAION<br><sup>2</sup>J√ºlich Supercomputing
                Center<br><sup>3</sup>School of Electrical and Electronic Engineering, University of Bristol
                <br><sup>4</sup>Open-Œ® (Open-Sci) Collective</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates corresponding authors</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2406.02061" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/LAION-AI/AIW" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2406.02061" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Teaser video-->
  <!-- <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <!-- Your video here -->

  <!-- End teaser video -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Large Language Models (LLMs) like closed weights ones GPT-3.5/4, Claude, Gemini or open weights ones like
              LLaMa 2/3, Mistral, Mixtral, and more recent ones Dbrx or Command R+ are often described as being
              instances of foundation models - that is, models that transfer strongly across various tasks and
              conditions in few-show or zero-shot manner, while exhibiting scaling laws that predict function
              improvement when increasing the pre-training scale. These claims of excelling in different functions and
              tasks rely on measurements taken across various sets of standardized benchmarks showing high scores for
              such models. We demonstrate here a dramatic breakdown of function and reasoning capabilities of
              state-of-the-art models trained at the largest available scales which claim strong function, using a
              simple, short, conventional problem formulated in concise natural language, easily solvable by humans. The
              breakdown is dramatic, as models also express strong overconfidence in their wrong solutions, while
              providing often non-sensical "reasoning"-like explanations akin to confabulations to justify and backup
              the validity of their clearly failed responses, making them sound plausible. Various standard
              interventions in an attempt to get the right solution, like various type of enhanced prompting, or urging
              the models to reconsider the wrong solutions again by multi step re-evaluation, fail. We take these
              initial observations to the scientific and technological community to stimulate urgent re-assessment of
              the claimed capabilities of current generation of LLMs, Such re-assessment also requires common action to
              create standardized benchmarks that would allow proper detection of such basic reasoning deficits that
              obviously manage to remain undiscovered by current state-of-the-art evaluation procedures and benchmarks.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->


  <!-- Image carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/carousel1.png" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Collapse of most SOTA LLMs on AIW problem.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/carousel2.png" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Failure of standardized benchmark MMLU to properly reflect and compare model basic reasoning capabilities
              as shown by strong discrepancy between AIW correct response rate vs MMLU average score. Many models, eg.
              Command R+, score 0 on AIW, but have high MMLU score.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/carousel3.png" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Collapse of most SOTA LLMs on AIW+ problem.
            </h2>
          </div>


        </div>
      </div>
    </div>
  </section>
  <!-- End image carousel -->


  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{nezhurina2024alice,
        title={Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models},
        author={Marianna Nezhurina and Lucia Cipolina-Kun and Mehdi Cherti and Jenia Jitsev},
        year={2024},
        journal={arXiv preprint arXiv:2406.02061},
        eprint={2406.02061},
        archivePrefix={arXiv},
        primaryClass={cs.LG}
  }</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Acknowledgments</h2>
          <div class="content has-text-justified">
            <p>
              We would like to express gratitude to all the people who are working on making code, models and data
              publicly available, advancing community based research and making research more reproducible.
              Specifically, we would like to thank all the members of the <a href="https://discord.gg/BZqhreFazY%7D%7D"
                target="_blank">LAION Discord server</a> community and <a href="https://discord.gg/GsKh4mBVcv%7D%7D"
                target="_blank">Open-Œ® (Open-Sci) Collective</a> for
              providing fruitful
              ground for scientific exchange and open-source development.
              </br>
              Marianna Nezhurina acknowledges funding by the Federal Ministry of Education and Research of Germany
              under grant no. 01IS22094B WestAI - AI Service Center West.
              </br>
              Lucia Cipolina-Kun acknowledges the Helmholtz Information & Data Science Academy (HIDA) for providing
              financial support enabling a short-term research stay at Juelich Supercomputing Center (JSC), Research
              Center Juelich (FZJ) to conduct research on foundation models.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <footer class=" footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the of this website, we just ask that you link back to this page in the
              footer.
              <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>